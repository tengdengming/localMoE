# LocalMoE LinuxæœåŠ¡å™¨å¿«é€Ÿéƒ¨ç½²æŒ‡å—

## ğŸš€ ä¸€é”®éƒ¨ç½² (æ¨è)

### å‰ææ¡ä»¶
- LinuxæœåŠ¡å™¨ (Ubuntu 20.04+ / CentOS 8+)
- 4x NVIDIA L40S GPU + 376GB RAM + 128 CPU
- NVIDIAé©±åŠ¨å·²å®‰è£…
- ç½‘ç»œè¿æ¥æ­£å¸¸

### éƒ¨ç½²å‘½ä»¤

```bash
# 1. ä¸Šä¼ ä»£ç åˆ°æœåŠ¡å™¨
git clone <your-repo-url> LocalMoE
cd LocalMoE

# 2. æ‰§è¡Œä¸€é”®éƒ¨ç½²
chmod +x deploy_linux_server.sh
./deploy_linux_server.sh

# 3. å¯åŠ¨æœåŠ¡
./deploy_linux_server.sh start
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸ‰

## ğŸ“‹ è¯¦ç»†æ­¥éª¤

### æ­¥éª¤1: å‡†å¤‡æœåŠ¡å™¨

```bash
# SSHè¿æ¥åˆ°æœåŠ¡å™¨
ssh user@your-server-ip

# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
free -h
nproc
df -h
```

### æ­¥éª¤2: ä¸Šä¼ ä»£ç 

```bash
# æ–¹æ³•1: Gitå…‹éš† (æ¨è)
git clone <your-repo-url> LocalMoE
cd LocalMoE

# æ–¹æ³•2: ä»æœ¬åœ°ä¸Šä¼ 
# åœ¨æœ¬åœ°æ‰§è¡Œ:
# rsync -avz --exclude='venv' --exclude='__pycache__' LocalMoE/ user@server-ip:~/LocalMoE/
```

### æ­¥éª¤3: æ‰§è¡Œéƒ¨ç½²

```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x deploy_linux_server.sh

# è¿è¡Œéƒ¨ç½²è„šæœ¬
./deploy_linux_server.sh
```

éƒ¨ç½²è„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆï¼š
- âœ… ç³»ç»Ÿä¾èµ–å®‰è£…
- âœ… Pythonç¯å¢ƒè®¾ç½®
- âœ… PyTorch + CUDAå®‰è£…
- âœ… vLLMå¼•æ“å®‰è£…
- âœ… é¡¹ç›®ä¾èµ–å®‰è£…
- âœ… ç¯å¢ƒé…ç½®
- âœ… systemdæœåŠ¡åˆ›å»º
- âœ… å®‰è£…æµ‹è¯•

### æ­¥éª¤4: å¯åŠ¨æœåŠ¡

```bash
# æ–¹æ³•1: å‰å°è¿è¡Œ (æµ‹è¯•ç”¨)
./deploy_linux_server.sh start

# æ–¹æ³•2: åå°æœåŠ¡ (ç”Ÿäº§ç”¨)
sudo systemctl start localmoe
sudo systemctl status localmoe
```

## ğŸ”§ é…ç½®é€‰æ‹©

### é»˜è®¤é…ç½® (13Bæ¨¡å‹)
```yaml
# configs/config.yaml
vllm:
  model_name: "meta-llama/Llama-2-13b-chat-hf"
  quantization: "awq"
  tensor_parallel_size: 4
  gpu_memory_utilization: 0.85
```

### é«˜æ€§èƒ½é…ç½® (7Bæ¨¡å‹)
```bash
# ä½¿ç”¨7Bæ¨¡å‹é…ç½®
cp configs/l40s_quantization_configs.yaml configs/config.yaml
# ç¼–è¾‘é€‰æ‹©: small_model_fp16
```

### å¤§æ¨¡å‹é…ç½® (70Bæ¨¡å‹)
```bash
# ä½¿ç”¨70Bæ¨¡å‹é…ç½®
cp configs/l40s_quantization_configs.yaml configs/config.yaml
# ç¼–è¾‘é€‰æ‹©: large_model_awq
```

## ğŸŒ éªŒè¯éƒ¨ç½²

### æ£€æŸ¥æœåŠ¡çŠ¶æ€

```bash
# æ£€æŸ¥æœåŠ¡
sudo systemctl status localmoe

# æ£€æŸ¥ç«¯å£
netstat -tlnp | grep 8000

# æ£€æŸ¥GPUä½¿ç”¨
nvidia-smi
```

### æµ‹è¯•API

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# æ¨ç†æµ‹è¯•
curl -X POST "http://localhost:8000/v1/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹LocalMoEç³»ç»Ÿ",
    "model_config": {
      "max_tokens": 100,
      "temperature": 0.7
    }
  }'
```

### è®¿é—®Webç•Œé¢

- **APIæ–‡æ¡£**: http://server-ip:8000/docs
- **å¥åº·æ£€æŸ¥**: http://server-ip:8000/health
- **æ¨¡å‹ä¿¡æ¯**: http://server-ip:8000/models

## ğŸ“Š ç›‘æ§å’Œç®¡ç†

### æœåŠ¡ç®¡ç†

```bash
# å¯åŠ¨æœåŠ¡
sudo systemctl start localmoe

# åœæ­¢æœåŠ¡
sudo systemctl stop localmoe

# é‡å¯æœåŠ¡
sudo systemctl restart localmoe

# æŸ¥çœ‹çŠ¶æ€
sudo systemctl status localmoe

# å¼€æœºè‡ªå¯
sudo systemctl enable localmoe
```

### æ—¥å¿—æŸ¥çœ‹

```bash
# ç³»ç»Ÿæ—¥å¿—
sudo journalctl -u localmoe -f

# åº”ç”¨æ—¥å¿—
tail -f logs/localmoe.log

# é”™è¯¯æ—¥å¿—
tail -f logs/error.log
```

### æ€§èƒ½ç›‘æ§

```bash
# GPUç›‘æ§
watch -n 1 nvidia-smi

# ç³»ç»Ÿç›‘æ§
htop

# ç½‘ç»œç›‘æ§
netstat -tlnp | grep 8000
```

## ğŸš¨ å¸¸è§é—®é¢˜

### 1. GPUå†…å­˜ä¸è¶³

```bash
# æ£€æŸ¥GPUä½¿ç”¨
nvidia-smi

# è§£å†³æ–¹æ¡ˆ: é™ä½å†…å­˜ä½¿ç”¨ç‡
# ç¼–è¾‘ configs/config.yaml
# vllm.gpu_memory_utilization: 0.8
```

### 2. ç«¯å£è¢«å ç”¨

```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tlnp | grep 8000

# è§£å†³æ–¹æ¡ˆ: ä¿®æ”¹ç«¯å£
# ç¼–è¾‘ .env
# LOCALMOE_PORT=8001
```

### 3. æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
huggingface-cli download meta-llama/Llama-2-13b-chat-hf --local-dir ./models/llama2-13b

# ä¿®æ”¹é…ç½®ä½¿ç”¨æœ¬åœ°è·¯å¾„
# configs/config.yaml
# vllm.model_name: "./models/llama2-13b"
```

### 4. ä¾èµ–å®‰è£…å¤±è´¥

```bash
# é‡æ–°åˆ›å»ºç¯å¢ƒ
rm -rf venv
./deploy_linux_server.sh
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–

### L40S GPUä¼˜åŒ–

```yaml
# æ¨èé…ç½®
vllm:
  quantization: "awq"              # L40Sæœ€ä½³é‡åŒ–
  gpu_memory_utilization: 0.85     # ä¿å®ˆå†…å­˜ä½¿ç”¨
  enable_prefix_caching: true      # åˆ©ç”¨å¤§æ˜¾å­˜
  use_v2_block_manager: true       # v2å†…å­˜ç®¡ç†
  max_num_batched_tokens: 16384    # å¤§æ‰¹å¤„ç†
```

### ç³»ç»Ÿä¼˜åŒ–

```bash
# GPUæ€§èƒ½æ¨¡å¼
sudo nvidia-smi -pm 1

# ç³»ç»Ÿå‚æ•°ä¼˜åŒ–
echo 'vm.swappiness=10' | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹éƒ¨ç½²è„šæœ¬å¸®åŠ©
./deploy_linux_server.sh --help

# è¿è¡Œæµ‹è¯•
./deploy_linux_server.sh test

# æŸ¥çœ‹é…ç½®
curl http://localhost:8000/v1/config
```

### æ”¶é›†è¯Šæ–­ä¿¡æ¯

```bash
# ç³»ç»Ÿä¿¡æ¯
uname -a
nvidia-smi
free -h
df -h

# æœåŠ¡çŠ¶æ€
sudo systemctl status localmoe
sudo journalctl -u localmoe --no-pager -n 50

# GPUçŠ¶æ€
nvidia-smi --query-gpu=name,memory.used,memory.total,temperature.gpu --format=csv
```

## ğŸ‰ éƒ¨ç½²å®Œæˆ

æ­å–œï¼æ‚¨å·²ç»æˆåŠŸéƒ¨ç½²äº†LocalMoEæœåŠ¡ã€‚

### ä¸‹ä¸€æ­¥

1. **é…ç½®æ¨¡å‹**: æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹å’Œé‡åŒ–æ–¹æ¡ˆ
2. **æ€§èƒ½è°ƒä¼˜**: æ ¹æ®å®é™…è´Ÿè½½è°ƒæ•´é…ç½®å‚æ•°
3. **ç›‘æ§è®¾ç½®**: é…ç½®Prometheuså’ŒGrafanaç›‘æ§
4. **å®‰å…¨é…ç½®**: è®¾ç½®é˜²ç«å¢™å’Œè®¿é—®æ§åˆ¶
5. **å¤‡ä»½ç­–ç•¥**: é…ç½®æ¨¡å‹å’Œé…ç½®æ–‡ä»¶å¤‡ä»½

### é‡è¦æé†’

- âœ… DeepSpeedå·²è¢«æ³¨é‡Šæ‰ï¼Œåªä½¿ç”¨vLLMå¼•æ“
- âœ… é…ç½®å·²é’ˆå¯¹L40S GPUä¼˜åŒ–
- âœ… æ”¯æŒAWQ/FP8é‡åŒ–ï¼Œå……åˆ†åˆ©ç”¨ç¡¬ä»¶ç‰¹æ€§
- âœ… ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼Œç¨³å®šå¯é 

äº«å—æ‚¨çš„é«˜æ€§èƒ½LocalMoEæ¨ç†æœåŠ¡ï¼ğŸš€
